{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0e2408",
   "metadata": {
    "id": "introduction"
   },
   "source": [
    "# Lecture 11: Hierarchical PyTorch and high level frameworks\n",
    "\n",
    "https://bit.ly/torch-intro3 / https://colab.research.google.com/drive/1ZITGTm6UED8qNs9HbBS45QCB3tk2UnvF?usp=sharing \n",
    "In this lecture, we dive into more advanced concepts in PyTorch, focusing on creating hierarchical neural networks.\n",
    "\n",
    "We'll also leverage PyTorch Lightning to streamline our training process and TensorBoard for logging and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff912ac",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup and Preliminaries\n",
    "\n",
    "Before we start, ensure that you have PyTorch Lightning, and TensorBoard installed in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a365165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U lightning tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc8abc7",
   "metadata": {
    "id": "import-libraries",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69fbdb6",
   "metadata": {
    "id": "data-generation"
   },
   "source": [
    "## Generating the Dataset\n",
    "Let's generate synthetic data based on the equation $y = \\cos(X_0 \\cdot 2.1 - 0.9) + X_2 \\cdot \\exp(-X_3^2)$.\n",
    "\n",
    "We will create a dataset where each sample will have features $[X_0, X_1, X_2, X_3]$ and the target $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38db2f8",
   "metadata": {
    "id": "generate-data"
   },
   "outputs": [],
   "source": [
    "num_samples = 100_000\n",
    "n_features = 4\n",
    "\n",
    "X = np.random.rand(num_samples, n_features) * 2 - 1  # Generate random samples in the range [-1, 1]\n",
    "y = np.cos(X[:, 0] * 2.1 - 0.9) + X[:, 2] * np.exp(-X[:, 3]**2)\n",
    "\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c5b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2691, -0.5700,  0.9034, -0.4306],\n",
      "        [ 0.6267, -0.1377, -0.0991, -0.4562],\n",
      "        [-0.9838, -0.2826, -0.6672, -0.7430],\n",
      "        ...,\n",
      "        [ 0.3953,  0.3029, -0.1189,  0.9153],\n",
      "        [ 0.6491,  0.7937, -0.6526, -0.7236],\n",
      "        [ 0.2078,  0.4156,  0.9341, -0.1918]])\n"
     ]
    }
   ],
   "source": [
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4e994",
   "metadata": {
    "id": "data-loader"
   },
   "source": [
    "Set up our data loader (no train/validation for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062cc842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8560,  0.8342, -1.3688,  ...,  0.9461,  0.5081,  1.7948])\n"
     ]
    }
   ],
   "source": [
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3560cec4",
   "metadata": {
    "id": "data-loader-setup",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "batch_size = 1024\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2f917",
   "metadata": {
    "id": "model-definition"
   },
   "source": [
    "## Defining the Hierarchical Model\n",
    "\n",
    "\n",
    "We will define a hierarchical neural network in PyTorch that incorporates feature engineering within the model itself.\n",
    "\n",
    "One sub-network will learn to transform inputs for the cosine term, while another learns the exponential term's effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e54a9c5",
   "metadata": {
    "id": "cosine-subnetwork",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size=64, n_features=4, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            *[\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, hidden_size),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ],\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648df20",
   "metadata": {},
   "source": [
    "## Integrating Sub-networks into the Hierarchical Model\n",
    "\n",
    "In this section, we combine the Cosine and Exponential sub-networks into a single hierarchical model that also incorporates the necessary feature transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d757b5",
   "metadata": {
    "id": "exponential-subnetwork",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class HierarchicalModel(nn.Module):\n",
    "    def __init__(self, hidden_size=64, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # All subnetworks get wrapped into this model!\n",
    "        self.cosine_argument = MLP(hidden_size=hidden_size, n_features=n_features, n_layers=n_layers)\n",
    "        self.exp_term = MLP(hidden_size=hidden_size, n_features=n_features, n_layers=n_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cos(self.cosine_argument(x)) + self.exp_term(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8107f",
   "metadata": {
    "id": "refactor-lightning"
   },
   "source": [
    "## Refactoring with PyTorch Lightning\n",
    "Next, we refactor our model to leverage PyTorch Lightning's features, simplifying training and logging procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a653a3d2",
   "metadata": {
    "id": "lightning-model",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class LitHierarchicalModel(L.LightningModule):\n",
    "    def __init__(self, hidden_size=64, n_layers=2, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        # Automatically track hyperparameters:\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = HierarchicalModel(\n",
    "            hidden_size=self.hparams[\"hidden_size\"],\n",
    "            n_layers=self.hparams[\"n_layers\"]\n",
    "        )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Declare optimizers *within* lightning model:\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams[\"learning_rate\"])\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "        # For tracking metrics:\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        # (Can also track anything else we want here.)\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d3df2",
   "metadata": {
    "id": "tensorboard-setup"
   },
   "source": [
    "## Setting Up TensorBoard Logging\n",
    "We'll use TensorBoard to visualize our training process, including loss curves and model graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d329de58",
   "metadata": {
    "id": "setup-logger"
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd08d99",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## Training the Model\n",
    "With everything set up, we can now train our model using PyTorch Lightning's Trainer, which integrates seamlessly with our TensorBoard logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "506e2d6c",
   "metadata": {
    "id": "train-model"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitHierarchicalModel(\n",
       "  (model): HierarchicalModel(\n",
       "    (cosine_argument): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (exp_term): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitHierarchicalModel(hidden_size=32, n_layers=2, learning_rate=1e-3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3877c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x2859b71d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=100, logger=logger)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f84e3e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | HierarchicalModel | 4.6 K \n",
      "--------------------------------------------\n",
      "4.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/98 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87:   0%|          | 0/98 [00:00<?, ?it/s, v_num=2]         "
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e9165f",
   "metadata": {
    "id": "tensorboard-visualization"
   },
   "source": [
    "## Visualizing Training with TensorBoard\n",
    "To view the training logs, you can try to launch TensorBoard from the terminal:\n",
    "```bash\n",
    "tensorboard --logdir tb_logs/\n",
    "```\n",
    "You can navigate to the provided URL to view loss curves, model graphs, and other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff61b0",
   "metadata": {},
   "source": [
    "# Lightning options\n",
    "\n",
    "https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "\n",
    "Many of these are state-of-the-art performance tricks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18334f20",
   "metadata": {},
   "source": [
    "# Karpathy Blog Post\n",
    "\n",
    "For any deep learning project, try:\n",
    "\n",
    "https://karpathy.github.io/2019/04/25/recipe/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39582d39",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## Practical Exercises\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Experiment with different architectures for the cosine and exponential sub-networks. How does changing the depth or width of these sub-networks affect performance?\n",
    "2. Utilize additional features of TensorBoard, such as custom scalars or model profiling, to gain deeper insights into the training process.\n",
    "3. Explore the advanced features of PyTorch Lightning, such as callbacks for model checkpointing and early stopping, to further improve your model training workflow.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
