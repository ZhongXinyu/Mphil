{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47468801",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principles of Data Science\n",
    "\n",
    "### Lecture 15: Confidence intervals\n",
    "\n",
    "_MPhil in Data Intensive Science_\n",
    "\n",
    "**University of Cambridge**\n",
    "\n",
    "<h2 style=\"color: blue\">Matt Kenzie</h2>\n",
    "\n",
    "[mk652@cam.ac.uk](mailto:mk652@cam.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08641518",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Confidence intervals\n",
    "\n",
    "- Today's lecture covers \n",
    "    - Confidence intervals\n",
    "    - Parameter estimation at physical limits / boundaries\n",
    "    - Constraints \n",
    "    - Feldman-Cousins interval estimation\n",
    "\n",
    "- Learning objectives:\n",
    "    - Understand what confidence intervals are and what they represent\n",
    "    - Understand the issues with classical intervals near physical boundaries\n",
    "    - Be able to deploy methods to circumvent these issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c66fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "- We have seen that MLE, least-squares and MoM all give us estimates and estimates of the uncertainty on those estimates\n",
    "    - Minimum variance bound approximation (inverse of Hessian matrix)\n",
    "    - Profiled log likelihood\n",
    "    \n",
    "- Wilks' theorem:\n",
    "    - $-2\\Delta\\ln L$ asymptotically approaches $\\Delta \\chi^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08ec3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence intervals\n",
    "\n",
    " - We have estimation methods to provide *point estimates* (a value) for parameters\n",
    " - But we are also interested in uncertainties (i.e. some confidence interval)\n",
    " - What is a *confidence interval*?\n",
    "     - We believe the *true* value of parameter, $\\theta$, lies within some interval, $\\theta_l < \\theta < \\theta_h$, $\\beta$% of the time\n",
    "     - This is the confidence interval at $\\beta$% C.L.\n",
    "     - If this is true the interval is said to \"*cover*\"\n",
    " - We typically quote uncertainties with $\\beta = 0.683$ corresponding to $1\\sigma$ of a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631cfc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Z-scores and confidence levels 1D\n",
    "\n",
    "<img src=\"plots/intervals1.png\" alt=\"drawing\" width=\"800\">\n",
    "<img src=\"plots/Zscores.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd8e91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Z-scores and confidence levels 2D\n",
    "<img src=\"plots/intervals2.png\" alt=\"drawing\" width=\"800\">\n",
    "<img src=\"plots/Zscores2.png\" alt=\"drawing\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d45563",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"plots/correlations.png\" alt=\"drawing\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddb22f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian credible intervals\n",
    "\n",
    "- No such concept of *confidence* for a Bayesian so instead called *credible* intervals\n",
    "- A Bayesian does not have a parameter estimate or confidence interval but instead has a *posterior p.d.f*\n",
    "- Construct a *credible interval* by requiring\n",
    "\n",
    "$$ \\beta = \\int_{\\theta_l}^{\\theta^h} p( \\theta | X ) d\\theta $$\n",
    "\n",
    "- There are infinitely many of these but standard is to find the central (or narrowest) such interval\n",
    "\n",
    "<img src=\"plots/credible_intervals1.png\" alt=\"drawing\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7d18e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For an upper limit can drop $\\theta_l$ down to $\\theta_{\\text{min}}$\n",
    "\n",
    "<img src=\"plots/credible_intervals2.png\" alt=\"drawing\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5d3e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neyman-Pearson (classical) intervals\n",
    "\n",
    "- For a frequentist the parameter, $\\theta$, is **fixed**\n",
    "- The interval is a member of a set of intervals such that\n",
    "\n",
    "$$p( \\theta \\in [ \\theta_l, \\theta_h] ) = \\beta $$\n",
    "\n",
    "- Interval is built from the p.d.f of the observation, $X$, given a *fixed* value of the parameters $\\theta$, $p(X; \\theta)$\n",
    "\n",
    "- <font color=\"red\">This is **NOT** the same as the posterior</font> as $\\theta$ is fixed\n",
    "\n",
    "- Then can build a *confidence belt* from these p.d.f.s for different fixed values of $\\theta$\n",
    "\n",
    "    <img src=\"plots/confidence_belt.png\" alt=\"drawing\" width=\"1000\">\n",
    "    \n",
    "- For some observation $X_0$ the *confidence interval* is constructed from the union of all $\\theta$ in the belt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4f960",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intermediate summary\n",
    "\n",
    "- This just formalises our discussion and definition of intervals\n",
    "- This is what we mean by an uncertainty\n",
    "- We now see that the frequentist starts to run into problems if parameters get near physical limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69b140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constraints in Fits\n",
    "\n",
    "- <font color=\"green\">*Discussion in lectures about applying constraints*</font>\n",
    "- Can enforce by mathematical reparameterisation\n",
    "- Or by inclusion of a constraint term in the likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd53f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"darkred\">*Musical interlude...*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efacfdd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimates and intervals near physical boundaries\n",
    "\n",
    "- The advantage of the Bayesian approach is that we can enforce a physical boundary\n",
    "- E.g. if parameter $\\mu \\geq 0$ then can have a prior:\n",
    "$$ p(\\mu) = 0 \\quad \\forall \\; \\mu <0 $$\n",
    "- But what does the frequentist do?\n",
    "\n",
    "<img src=\"plots/conf_belt_norm.png\" alt=\"drawing\">\n",
    "\n",
    "- It is possible to measure a value which gives an <font color=\"blue\">**empty**</font> confidence interval!\n",
    "- The interval will then suffer from <font color=\"blue\">**undercoverage**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47207758",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A standard example of fitting a signal\n",
    "\n",
    "- Imagine fitting a small signal on top of a small background\n",
    "- I may want to enforce that the signal yield is positive\n",
    "- Even if I don't my p.d.f has to be positive everywhere so there will be a lower limit to the yield I can fit\n",
    "\n",
    "<img src=\"plots/under_coverage_fit.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e7cba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If I enforce the limit to the parameter it will skew my error matrix\n",
    "- The (profile) likelihood runs up to a boundary where it cannot be computed\n",
    "\n",
    "<img src=\"plots/under_coverage1.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fad0f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If I run several toys I see that I do not get a nice normal distribution\n",
    "- Instead the values \"stack up\" at the boundary\n",
    "- The result is that I have a very <font color=\"blue\">**serious coverage problem**</font>\n",
    "\n",
    "<img src=\"plots/under_coverage2.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a7768",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Flip-flopping\n",
    "\n",
    "- You may think one way around this issue is to:\n",
    "   1) quote central value and uncertainty above some threshold\n",
    "   2) quote upper limits below some threshold up to the boundary\n",
    "   3) quote the upper limit at the boundary for any value beyond the boundary\n",
    "   \n",
    "- This leads to the wrong coverage in many regions \n",
    "- And discontinuities in the confidence belt (known as *flip-flopping*)\n",
    "\n",
    "<img src=\"plots/flip_flop.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785b200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Feldman-Cousins method\n",
    "\n",
    "- A beautiful, and purely frequentist approach, to solve the problem\n",
    "- Based on the assumption that if you want the correct coverage then why not construct the interval that has the correct coverage by defintion\n",
    "- This requires producing simulation samples and then computing where 68% lie\n",
    "- For a given $X$ start from ML estimate of $\\hat{\\mu}$ with the bound applied\n",
    "- The for some fixed value of $\\mu$ find the log-likelihood-ratio\n",
    "\n",
    "$$ R = \\frac{p(X|\\mu)}{p(X|\\hat{\\mu})} $$\n",
    "\n",
    "- Add values to $X$ from higher to lower $R$ (i.e. working outwards from the best fit point) until the desired probability content is reached\n",
    "\n",
    "- The code for this is in the lecture notes\n",
    "\n",
    "<img src=\"plots/fc_norm.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a32e25",
   "metadata": {},
   "source": [
    "### Feldman Cousins\n",
    "\n",
    "- A more formulaic MC simulation based approach:\n",
    "    \n",
    "    1) Run ML fit to determine $-2\\ln L(\\hat{\\mu}$) at best fit point $\\hat{\\mu}$\n",
    "    2) Pick some other test value $\\mu_0$ and compute $-2\\ln L(\\mu_0)$\n",
    "    3) Now compute the LLR between these points, $R = -2\\Delta \\ln L(\\mu_0)$\n",
    "    4) Simulate a set of toy experiments from the parameters at the point $\\mu_0$\n",
    "    5) Compute the LLR for each of these $R'$\n",
    "    6) The 1-CL value at the scan point is given by the fraction of toys for which $R' > R$.\n",
    "    \n",
    "<img src=\"plots/fc_example.png\" alt=\"drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96f171",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# End of Lecture 15\n",
    "\n",
    "By the end of this lecture you should:\n",
    "   - Understand what confidence intervals are and what they represent\n",
    "   - Understand the issues with classical intervals near physical boundaries\n",
    "   - Be able to deploy methods to circumvent these issues"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
